{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96f3b52d",
   "metadata": {},
   "source": [
    "# What is a Feedforward Neural Network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bcc1d",
   "metadata": {},
   "source": [
    "## -> A feedforward neural network is one of the simplest types of artificial neural networks devised. In this network, the information moves in only one direction—forward—from the input nodes, through the hidden nodes (if any), and to the output nodes. There are no cycles or loops in the network. Feedforward neural networks were the first type of artificial neural network invented and are simpler than their counterparts like recurrent neural networks and convolutional neural networks.\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://b2633864.smushcdn.com/2633864/wp-content/uploads/2021/04/feedforward-neural-networks.png?lossy=2&strip=1&webp=1\" alt=\"2\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dfe5d",
   "metadata": {},
   "source": [
    "# Architecture of Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2345e8c",
   "metadata": {},
   "source": [
    "## -> The architecture of a feedforward neural network consists of three types of layers: the input layer, hidden layers, and the output layer. Each layer is made up of units known as neurons, and the layers are interconnected by weights.\n",
    "\n",
    "# Input Layer: \n",
    "## This layer consists of neurons that receive inputs and pass them on to the next layer. The number of neurons in the input layer is determined by the dimensions of the input data.\n",
    "# Hidden Layers:\n",
    "## These layers are not exposed to the input or output and can be considered as the computational engine of the neural network. Each hidden layer's neurons take the weighted sum of the outputs from the previous layer, apply an activation function, and pass the result to the next layer. The network can have zero or more hidden layers.\n",
    "\n",
    "# Output Layer: \n",
    "## The final layer that produces the output for the given inputs. The number of neurons in the output layer depends on the number of possible outputs the network is designed to produce.\n",
    "# NOTE :-\n",
    "## Each neuron in one layer is connected to every neuron in the next layer, making this a fully connected network. The strength of the connection between neurons is represented by weights, and learning in a neural network involves updating these weights based on the error of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e0f93",
   "metadata": {},
   "source": [
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://www.scaler.com/topics/images/neural-networks-feed-forward-architecture.webp\" alt=\"2\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d9973",
   "metadata": {},
   "source": [
    "# How Feedforward Neural Networks Work\n",
    "## -> The working of a feedforward neural network involves two phases: the feedforward phase and the backpropagation phase.\n",
    "\n",
    "# Feedforward Phase: \n",
    "## In this phase, the input data is fed into the network, and it propagates forward through the network. At each hidden layer, the weighted sum of the inputs is calculated and passed through an activation function, which introduces non-linearity into the model. This process continues until the output layer is reached, and a prediction is made.\n",
    "# Backpropagation Phase: \n",
    "## Once a prediction is made, the error (difference between the predicted output and the actual output) is calculated. This error is then propagated back through the network, and the weights are adjusted to minimize this error. The process of adjusting weights is typically done using a gradient descent optimization algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0b0a2",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "## -> Activation functions play a crucial role in feedforward neural networks. They introduce non-linear properties to the network, which allows the model to learn more complex patterns. Common activation functions include the sigmoid, tanh, and ReLU (Rectified Linear Unit)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b6126",
   "metadata": {},
   "source": [
    "# Training Feedforward Neural Networks\n",
    "## Training a feedforward neural network involves using a dataset to adjust the weights of the connections between neurons. This is done through an iterative process where the dataset is passed through the network multiple times, and each time, the weights are updated to reduce the error in prediction. This process is known as gradient descent, and it continues until the network performs satisfactorily on the training data.\n",
    "\n",
    "# Applications of Feedforward Neural Networks\n",
    "## Feedforward neural networks are used in a variety of machine learning tasks including:\n",
    "\n",
    "* Pattern recognition\n",
    "* Classification tasks\n",
    "* Regression analysis\n",
    "* Image recognition\n",
    "* Time series prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c985e",
   "metadata": {},
   "source": [
    "# Challenges and Limitations\n",
    "## -> While feedforward neural networks are powerful, they come with their own set of challenges and limitations. One of the main challenges is the choice of the number of hidden layers and the number of neurons in each layer, which can significantly affect the performance of the network. Overfitting is another common issue where the network learns the training data too well, including the noise, and performs poorly on new, unseen data.\n",
    "\n",
    "## -> In conclusion, feedforward neural networks are a foundational concept in the field of neural networks and deep learning. They provide a straightforward approach to modeling data and making predictions and have paved the way for more advanced neural network architectures used in modern artificial intelligence applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7e8ab",
   "metadata": {},
   "source": [
    "## Working in simple words :-\n",
    "\n",
    "## -> FNN is work on the equation of line (y=mx+c/z=wx+b)...\n",
    "\n",
    "### where :- \n",
    "#### w/m == weight  (-> it assign randomally....  in the modal)\n",
    "#### c/b == bais (INTERCEPT)\n",
    "## Activation Function :- \n",
    "\n",
    "### -> It is use by nn to classify 2 classes. it perfect with that ....\n",
    "<pre><h1>\n",
    "             1\n",
    "Sigmoid=   __________\n",
    "            1-e **-z(line equation)\n",
    "</h1></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cacfd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47625c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00333a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=dataset['data']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb91fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset['target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebab287e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52103744, 0.0226581 , 0.54598853, ..., 0.91202749, 0.59846245,\n",
       "        0.41886396],\n",
       "       [0.64314449, 0.27257355, 0.61578329, ..., 0.63917526, 0.23358959,\n",
       "        0.22287813],\n",
       "       [0.60149557, 0.3902604 , 0.59574321, ..., 0.83505155, 0.40370589,\n",
       "        0.21343303],\n",
       "       ...,\n",
       "       [0.45525108, 0.62123774, 0.44578813, ..., 0.48728522, 0.12872068,\n",
       "        0.1519087 ],\n",
       "       [0.64456434, 0.66351031, 0.66553797, ..., 0.91065292, 0.49714173,\n",
       "        0.45231536],\n",
       "       [0.03686876, 0.50152181, 0.02853984, ..., 0.        , 0.25744136,\n",
       "        0.10068215]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sacle=MinMaxScaler()\n",
    "x_scale=sacle.fit_transform(x)\n",
    "x_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78efeb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(x_scale,y,test_size=0.2,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa31ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3588a659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Modal=Sequential([\n",
    " Dense(32,input_shape=x[0].shape,activation=\"relu\"),\n",
    " Dense(100,activation=\"relu\"),\n",
    " Dense(1,activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4eb720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 1s 35ms/step - loss: 0.6764 - accuracy: 0.6676 - val_loss: 0.6579 - val_accuracy: 0.7802\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6376 - accuracy: 0.7802 - val_loss: 0.6293 - val_accuracy: 0.7912\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6000 - accuracy: 0.7885 - val_loss: 0.5949 - val_accuracy: 0.8242\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5610 - accuracy: 0.8269 - val_loss: 0.5574 - val_accuracy: 0.8462\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5207 - accuracy: 0.8489 - val_loss: 0.5232 - val_accuracy: 0.8462\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4811 - accuracy: 0.8654 - val_loss: 0.4771 - val_accuracy: 0.8462\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.8654 - val_loss: 0.4317 - val_accuracy: 0.8681\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8764 - val_loss: 0.3948 - val_accuracy: 0.8571\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.8791 - val_loss: 0.3508 - val_accuracy: 0.8791\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3242 - accuracy: 0.8929 - val_loss: 0.3099 - val_accuracy: 0.9121\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2950 - accuracy: 0.8984 - val_loss: 0.2867 - val_accuracy: 0.9121\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2735 - accuracy: 0.8984 - val_loss: 0.2670 - val_accuracy: 0.9121\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2581 - accuracy: 0.8929 - val_loss: 0.2604 - val_accuracy: 0.9121\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2379 - accuracy: 0.9148 - val_loss: 0.2243 - val_accuracy: 0.9341\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2270 - accuracy: 0.9121 - val_loss: 0.2173 - val_accuracy: 0.9231\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2222 - accuracy: 0.9066 - val_loss: 0.2271 - val_accuracy: 0.9231\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2078 - accuracy: 0.9203 - val_loss: 0.1906 - val_accuracy: 0.9341\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1956 - accuracy: 0.9258 - val_loss: 0.1822 - val_accuracy: 0.9231\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1889 - accuracy: 0.9258 - val_loss: 0.1784 - val_accuracy: 0.9231\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1901 - accuracy: 0.9176 - val_loss: 0.1574 - val_accuracy: 0.9341\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1776 - accuracy: 0.9396 - val_loss: 0.1635 - val_accuracy: 0.9231\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.9341 - val_loss: 0.1421 - val_accuracy: 0.9341\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1616 - accuracy: 0.9396 - val_loss: 0.1389 - val_accuracy: 0.9341\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.9396 - val_loss: 0.1388 - val_accuracy: 0.9231\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1475 - accuracy: 0.9396 - val_loss: 0.1250 - val_accuracy: 0.9451\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1386 - accuracy: 0.9505 - val_loss: 0.1276 - val_accuracy: 0.9341\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1357 - accuracy: 0.9588 - val_loss: 0.1137 - val_accuracy: 0.9560\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1290 - accuracy: 0.9698 - val_loss: 0.1078 - val_accuracy: 0.9670\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1242 - accuracy: 0.9670 - val_loss: 0.1030 - val_accuracy: 0.9560\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1217 - accuracy: 0.9698 - val_loss: 0.0970 - val_accuracy: 0.9670\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1158 - accuracy: 0.9698 - val_loss: 0.0933 - val_accuracy: 0.9670\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1114 - accuracy: 0.9753 - val_loss: 0.0881 - val_accuracy: 0.9670\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1075 - accuracy: 0.9753 - val_loss: 0.0855 - val_accuracy: 0.9670\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1033 - accuracy: 0.9780 - val_loss: 0.0804 - val_accuracy: 0.9780\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 0.9725 - val_loss: 0.0782 - val_accuracy: 0.9560\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0978 - accuracy: 0.9808 - val_loss: 0.0749 - val_accuracy: 0.9560\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0942 - accuracy: 0.9808 - val_loss: 0.0703 - val_accuracy: 0.9780\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0912 - accuracy: 0.9753 - val_loss: 0.0679 - val_accuracy: 0.9780\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9753 - val_loss: 0.0663 - val_accuracy: 0.9670\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0880 - accuracy: 0.9808 - val_loss: 0.0640 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9780 - val_loss: 0.0619 - val_accuracy: 0.9780\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0863 - accuracy: 0.9725 - val_loss: 0.0614 - val_accuracy: 0.9780\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.9890 - val_loss: 0.0576 - val_accuracy: 0.9890\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9753 - val_loss: 0.0570 - val_accuracy: 0.9780\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0780 - accuracy: 0.9780 - val_loss: 0.0557 - val_accuracy: 0.9780\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9808 - val_loss: 0.0545 - val_accuracy: 0.9780\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.0540 - val_accuracy: 0.9780\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.0504 - val_accuracy: 0.9890\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9753 - val_loss: 0.0499 - val_accuracy: 0.9780\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0687 - accuracy: 0.9808 - val_loss: 0.0487 - val_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23dfe32ab00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Modal.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "Modal.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c71d8b-c5d3-4582-9acb-50d0cf478ceb",
   "metadata": {},
   "source": [
    "# Activation Function :-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2734fdb-3075-4283-ab70-1acf3c509301",
   "metadata": {
    "tags": []
   },
   "source": [
    "<pre><h2> Activation function is a simple mathematical operation which is use to change the shape of line and transform the line according to our data in the graph, just to categorize the class.\n",
    "\n",
    "Type of activation function?\n",
    "\n",
    "1.) Sigmoid\n",
    "\n",
    "2.) tanh\n",
    "\n",
    "3.) softmax\n",
    "\n",
    "4.) Relu\n",
    "\n",
    "5.) LeakyRelu\n",
    "</pre></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad3898-9112-469f-a23f-44a298a46cce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.) Sigmoid :-\n",
    "## equation of sigmoid:\n",
    "\n",
    "## p(1)=1/(1-e**(-z))\n",
    "\n",
    "# e= Euler's constant == 2.718281828459045…\n",
    "\n",
    "# z= equation of line(summation part of a neural in deep neural network)\n",
    "\n",
    "## while split the the class if class count is 2 only.\n",
    "\n",
    "\n",
    "# sigmoid function always transform the equation of line(summation part of a neuron between 0 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b6da4-b57e-44f3-8320-cf6d5e3e8e6b",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.99978&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b6196b",
   "metadata": {},
   "source": [
    "##  Sigmod is a activation function which change the line and try to achieved more and more data point with minimum loss ........\n",
    "\n",
    "## It work good with 2 class...\n",
    "\n",
    "## sigmoid function convert the summation part(equation of line, denote by small z) between 0 and 1.\n",
    "\n",
    "## At hidden layer sigmoid function is used to get complex pattern from the data to classify the datapoint.\n",
    "\n",
    "## To classify the data sigmoid function simply transform(change the equation of line in Non-linear fashion)\n",
    "\n",
    "## Sigmoid function help us to calculate the probability at output layer ( when we have two class in a dataset) most important : it always calculate the probability of positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5125b46",
   "metadata": {},
   "source": [
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://cdn.prod.website-files.com/5d7b77b063a9066d83e1209c/60d243324bcba9144370e261_Screenshot%20(205).jpg\" alt=\"2\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f9245",
   "metadata": {},
   "source": [
    "# 2.) Softmax :-¶\n",
    "\n",
    "## It good for multi class.\n",
    "## it use in output layer.\n",
    "## it never use in hidden layer.\n",
    "## Define:- The softmax transform the raw score(logits) into probability that sum to one...\n",
    "## Note :- logits are the outputs of a neural network before the activation function is applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae479e",
   "metadata": {},
   "source": [
    "# Disadvantage:\n",
    "\n",
    "## > it is computationally very expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff44f94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of orange: 0.12470760388881726\n",
      "probability of banana: 0.041511585967019315\n",
      "probability of cherry: 0.8337808101441634\n"
     ]
    }
   ],
   "source": [
    "z_orange=3.1\n",
    "z_banana=2.0\n",
    "z_cherry=5\n",
    "\n",
    "e=2.71828  # euler constant\n",
    "\n",
    "probability_z_orange=e**(z_orange)/((e**z_orange)+(e**z_banana)+(e**z_cherry))\n",
    "\n",
    "print(\"probability of orange:\",probability_z_orange)\n",
    "\n",
    "probability_z_banana=e**(z_banana)/((e**z_orange)+(e**z_banana)+(e**z_cherry))\n",
    "print(\"probability of banana:\",probability_z_banana)\n",
    "\n",
    "probability_z_cherry=e**(z_cherry)/((e**z_orange)+(e**z_banana)+(e**z_cherry))\n",
    "print(\"probability of cherry:\",probability_z_cherry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3888f9",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://ambrapaliaidata.blob.core.windows.net/ai-storage/articles/2_xyfKBMo.png\" alt=\"2\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e6b3d6",
   "metadata": {},
   "source": [
    "# Note about above :-\n",
    "## 1.) There \"e\" is euler constant.\n",
    "## 2.) z1,z2,z3----z.n is class_logits on which activation func. is applied..\n",
    "## 3.) In above image it calculate the probablity for z1 class.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5c2fc",
   "metadata": {},
   "source": [
    "# _______________________________________________________________\n",
    "# 3.) Tan h (Hyperbolic Tangent):-\n",
    "\n",
    "## It is a activation function which leran the complex dataset and use for train the modal.\n",
    "\n",
    "## It shape same as sigmode (\"S\") but range is different...\n",
    "\n",
    "## Tan h lies b\\w 1 to -1...\n",
    "\n",
    "## sigmoid lies b\\w 1 to 0...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120a264",
   "metadata": {},
   "source": [
    "# Formula :-\n",
    "\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F11779392%2Fde7f0796bbbd001e196cdc117fc47895%2FTanh.jpg?generation=1665561725954806&alt=media\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d60ebc",
   "metadata": {},
   "source": [
    "# Graph :- \n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://mathworld.wolfram.com/images/interactive/TanhReal.gif\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0672e25",
   "metadata": {},
   "source": [
    "## Making the tan h graph by Code :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4dab760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152c1dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.        , -3.88888889, -2.77777778, -1.66666667, -0.55555556,\n",
       "        0.55555556,  1.66666667,  2.77777778,  3.88888889,  5.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.linspace(-5,5,10) # it return a array which contain 10 value b/w -10 - 10 ..\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5c07b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tan_h=np.tanh(a) # it range the value a b/w 1 to -1 .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a377807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a,tan_h)\n",
    "plt.xlabel(\"A\")\n",
    "plt.ylabel(\"Tan_h\")\n",
    "plt.title(\"Tan_h Graph\")\n",
    "plt.axhline(0,color='black',linewidth=0.5)\n",
    "plt.axvline(0,color='black',linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e53c8",
   "metadata": {},
   "source": [
    "# 4.) RELU (Rectified  linear unit) :-\n",
    "\n",
    "## -> It is a most comman activation function which work on given below formula.\n",
    "## -> If z is greater than zero than it give the z as output otherwise zero.\n",
    "## -> It use less memory for computation as compare too tanh or sigmoid this also know as The vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e638c7e",
   "metadata": {},
   "source": [
    "# Formula :- \n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"data:image/png;base64,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\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19c7b2",
   "metadata": {},
   "source": [
    "# Graph :- \n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*XxxiA0jJvPrHEJHD4z893g.png\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528997dc",
   "metadata": {},
   "source": [
    "# Note :-\n",
    "## -> what is a z ??\n",
    "### -> Neuron summation part is z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539efe15",
   "metadata": {},
   "source": [
    "# 5.) Leaky RELU :-\n",
    "\n",
    "## -> Leaky relu is nothing it is the solution of relu problem which is given below and this problem is know as Dying ReLU problem..\n",
    "## -> In which if z is greater than zero then it give z otherwise α *z.\n",
    "## -> α  is nothing it is slope (commanly α  value 0.01 but we can able too change it.).by scientific experiment scientist found l.relu give good result at 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507a5abb",
   "metadata": {},
   "source": [
    "# Dying ReLU problem :-\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"data:image/png;base64,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\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebbded7",
   "metadata": {},
   "source": [
    "# Formula :- \n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"data:image/png;base64,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\" alt=\"2\" border=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59f4bf",
   "metadata": {},
   "source": [
    "# Graph :- \n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"data:image/png;base64,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\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586ceb9",
   "metadata": {},
   "source": [
    "# __________________________________________________________\n",
    "# Applying Different - Different activation function in neural network :-\n",
    "## 1.) Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b81f4fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 0.6568 - accuracy: 0.6319 - val_loss: 0.6672 - val_accuracy: 0.6044\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6519 - accuracy: 0.6319 - val_loss: 0.6657 - val_accuracy: 0.6044\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6487 - accuracy: 0.6319 - val_loss: 0.6596 - val_accuracy: 0.6044\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6449 - accuracy: 0.6319 - val_loss: 0.6565 - val_accuracy: 0.6044\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6403 - accuracy: 0.6319 - val_loss: 0.6509 - val_accuracy: 0.6044\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6319 - val_loss: 0.6457 - val_accuracy: 0.6044\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.6319 - val_loss: 0.6409 - val_accuracy: 0.6044\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.6319 - val_loss: 0.6350 - val_accuracy: 0.6044\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6160 - accuracy: 0.6319 - val_loss: 0.6254 - val_accuracy: 0.6044\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6078 - accuracy: 0.6319 - val_loss: 0.6155 - val_accuracy: 0.6044\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5984 - accuracy: 0.6319 - val_loss: 0.6066 - val_accuracy: 0.6044\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5857 - accuracy: 0.6346 - val_loss: 0.5910 - val_accuracy: 0.6154\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5725 - accuracy: 0.6621 - val_loss: 0.5759 - val_accuracy: 0.6374\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5582 - accuracy: 0.6758 - val_loss: 0.5610 - val_accuracy: 0.6484\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5428 - accuracy: 0.6758 - val_loss: 0.5454 - val_accuracy: 0.6484\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5255 - accuracy: 0.7005 - val_loss: 0.5284 - val_accuracy: 0.6703\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5077 - accuracy: 0.7473 - val_loss: 0.5077 - val_accuracy: 0.7473\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4887 - accuracy: 0.8077 - val_loss: 0.4862 - val_accuracy: 0.8022\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.8544 - val_loss: 0.4663 - val_accuracy: 0.8132\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4509 - accuracy: 0.8324 - val_loss: 0.4497 - val_accuracy: 0.8022\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8736 - val_loss: 0.4247 - val_accuracy: 0.8571\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.8984 - val_loss: 0.4025 - val_accuracy: 0.8901\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.9176 - val_loss: 0.3817 - val_accuracy: 0.9121\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.9093 - val_loss: 0.3661 - val_accuracy: 0.8791\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8984 - val_loss: 0.3472 - val_accuracy: 0.8791\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.9176 - val_loss: 0.3242 - val_accuracy: 0.9560\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3210 - accuracy: 0.9231 - val_loss: 0.3099 - val_accuracy: 0.9231\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3055 - accuracy: 0.9148 - val_loss: 0.2955 - val_accuracy: 0.9121\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2909 - accuracy: 0.9341 - val_loss: 0.2767 - val_accuracy: 0.9780\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2790 - accuracy: 0.9368 - val_loss: 0.2646 - val_accuracy: 0.9670\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2665 - accuracy: 0.9341 - val_loss: 0.2519 - val_accuracy: 0.9670\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2553 - accuracy: 0.9396 - val_loss: 0.2396 - val_accuracy: 0.9670\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2451 - accuracy: 0.9368 - val_loss: 0.2286 - val_accuracy: 0.9780\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.9368 - val_loss: 0.2193 - val_accuracy: 0.9670\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2270 - accuracy: 0.9368 - val_loss: 0.2084 - val_accuracy: 0.9670\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2193 - accuracy: 0.9368 - val_loss: 0.1998 - val_accuracy: 0.9670\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2123 - accuracy: 0.9368 - val_loss: 0.1943 - val_accuracy: 0.9670\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2056 - accuracy: 0.9368 - val_loss: 0.1850 - val_accuracy: 0.9670\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1994 - accuracy: 0.9368 - val_loss: 0.1784 - val_accuracy: 0.9670\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1940 - accuracy: 0.9396 - val_loss: 0.1718 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1889 - accuracy: 0.9396 - val_loss: 0.1646 - val_accuracy: 0.9670\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1840 - accuracy: 0.9396 - val_loss: 0.1616 - val_accuracy: 0.9780\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1787 - accuracy: 0.9423 - val_loss: 0.1541 - val_accuracy: 0.9670\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1750 - accuracy: 0.9505 - val_loss: 0.1494 - val_accuracy: 0.9670\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1711 - accuracy: 0.9451 - val_loss: 0.1466 - val_accuracy: 0.9780\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1665 - accuracy: 0.9451 - val_loss: 0.1405 - val_accuracy: 0.9670\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1633 - accuracy: 0.9505 - val_loss: 0.1377 - val_accuracy: 0.9670\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1601 - accuracy: 0.9478 - val_loss: 0.1338 - val_accuracy: 0.9670\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9478 - val_loss: 0.1298 - val_accuracy: 0.9670\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1538 - accuracy: 0.9478 - val_loss: 0.1267 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23d82eddc00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=load_breast_cancer()\n",
    "x=dataset['data']\n",
    "y=dataset['target']\n",
    "sacle=MinMaxScaler()\n",
    "x_scale=sacle.fit_transform(x)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scale,y,test_size=0.2,random_state=45)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "Modal=Sequential([\n",
    " Dense(32,input_shape=x[0].shape,activation=\"sigmoid\"),\n",
    " Dense(100,activation=\"sigmoid\"),\n",
    " Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "Modal.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "Modal.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00510a",
   "metadata": {},
   "source": [
    "# 2.) Relu :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2460a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 27ms/step - loss: 0.6985 - accuracy: 0.3681 - val_loss: 0.6699 - val_accuracy: 0.4945\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6582 - accuracy: 0.7500 - val_loss: 0.6397 - val_accuracy: 0.9011\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.9066 - val_loss: 0.6046 - val_accuracy: 0.8901\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5803 - accuracy: 0.8901 - val_loss: 0.5583 - val_accuracy: 0.8901\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5291 - accuracy: 0.9038 - val_loss: 0.5053 - val_accuracy: 0.8901\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.8929 - val_loss: 0.4459 - val_accuracy: 0.8901\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8956 - val_loss: 0.3900 - val_accuracy: 0.8901\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8956 - val_loss: 0.3389 - val_accuracy: 0.8901\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3150 - accuracy: 0.9011 - val_loss: 0.2958 - val_accuracy: 0.9231\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.9121 - val_loss: 0.2545 - val_accuracy: 0.9121\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2456 - accuracy: 0.9176 - val_loss: 0.2290 - val_accuracy: 0.9341\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2218 - accuracy: 0.9231 - val_loss: 0.2079 - val_accuracy: 0.9341\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2026 - accuracy: 0.9203 - val_loss: 0.1956 - val_accuracy: 0.9341\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1894 - accuracy: 0.9286 - val_loss: 0.1747 - val_accuracy: 0.9231\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.9286 - val_loss: 0.1601 - val_accuracy: 0.9231\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1654 - accuracy: 0.9341 - val_loss: 0.1528 - val_accuracy: 0.9231\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9478 - val_loss: 0.1363 - val_accuracy: 0.9560\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1497 - accuracy: 0.9396 - val_loss: 0.1326 - val_accuracy: 0.9341\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1407 - accuracy: 0.9423 - val_loss: 0.1197 - val_accuracy: 0.9560\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1317 - accuracy: 0.9478 - val_loss: 0.1221 - val_accuracy: 0.9341\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1263 - accuracy: 0.9670 - val_loss: 0.1049 - val_accuracy: 0.9670\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1187 - accuracy: 0.9615 - val_loss: 0.1075 - val_accuracy: 0.9560\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1153 - accuracy: 0.9560 - val_loss: 0.0941 - val_accuracy: 0.9670\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1085 - accuracy: 0.9670 - val_loss: 0.0921 - val_accuracy: 0.9670\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1072 - accuracy: 0.9615 - val_loss: 0.0889 - val_accuracy: 0.9670\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1012 - accuracy: 0.9643 - val_loss: 0.0825 - val_accuracy: 0.9780\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.9670 - val_loss: 0.0772 - val_accuracy: 0.9780\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1020 - accuracy: 0.9588 - val_loss: 0.0747 - val_accuracy: 0.9780\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0912 - accuracy: 0.9698 - val_loss: 0.0790 - val_accuracy: 0.9670\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9698 - val_loss: 0.0695 - val_accuracy: 0.9670\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9753 - val_loss: 0.0665 - val_accuracy: 0.9780\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9670 - val_loss: 0.0645 - val_accuracy: 0.9670\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9780 - val_loss: 0.0619 - val_accuracy: 0.9890\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0785 - accuracy: 0.9753 - val_loss: 0.0659 - val_accuracy: 0.9670\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0787 - accuracy: 0.9698 - val_loss: 0.0580 - val_accuracy: 0.9890\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9780 - val_loss: 0.0566 - val_accuracy: 0.9780\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 0.9753 - val_loss: 0.0611 - val_accuracy: 0.9670\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9725 - val_loss: 0.0536 - val_accuracy: 0.9890\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0707 - accuracy: 0.9780 - val_loss: 0.0540 - val_accuracy: 0.9890\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0703 - accuracy: 0.9753 - val_loss: 0.0510 - val_accuracy: 0.9780\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9780 - val_loss: 0.0497 - val_accuracy: 0.9780\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9780 - val_loss: 0.0503 - val_accuracy: 0.9890\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0672 - accuracy: 0.9753 - val_loss: 0.0478 - val_accuracy: 0.9890\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9753 - val_loss: 0.0477 - val_accuracy: 0.9890\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 0.0457 - val_accuracy: 0.9780\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.9808 - val_loss: 0.0462 - val_accuracy: 0.9890\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9780 - val_loss: 0.0450 - val_accuracy: 0.9890\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.0431 - val_accuracy: 0.9780\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9808 - val_loss: 0.0429 - val_accuracy: 0.9890\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9780 - val_loss: 0.0484 - val_accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23d82b7e7a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=load_breast_cancer()\n",
    "x=dataset['data']\n",
    "y=dataset['target']\n",
    "sacle=MinMaxScaler()\n",
    "x_scale=sacle.fit_transform(x)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scale,y,test_size=0.2,random_state=45)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "Modal=Sequential([\n",
    " Dense(32,input_shape=x[0].shape,activation=\"relu\"),\n",
    " Dense(100,activation=\"relu\"),\n",
    " Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "Modal.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "Modal.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6bb8e",
   "metadata": {},
   "source": [
    "# 3.) Tanh :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b84eb020",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 28ms/step - loss: 1.2982 - accuracy: 0.2500 - val_loss: 0.8845 - val_accuracy: 0.4396\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8436 - accuracy: 0.5989 - val_loss: 0.8607 - val_accuracy: 0.5714\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7741 - accuracy: 0.6071 - val_loss: 0.7521 - val_accuracy: 0.5055\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6697 - accuracy: 0.6209 - val_loss: 0.6531 - val_accuracy: 0.6374\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.6868 - val_loss: 0.5867 - val_accuracy: 0.6374\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5432 - accuracy: 0.7225 - val_loss: 0.5345 - val_accuracy: 0.7363\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4819 - accuracy: 0.8187 - val_loss: 0.4900 - val_accuracy: 0.7692\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.8379 - val_loss: 0.4478 - val_accuracy: 0.7912\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8489 - val_loss: 0.4087 - val_accuracy: 0.8242\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8654 - val_loss: 0.3849 - val_accuracy: 0.8242\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8681 - val_loss: 0.3558 - val_accuracy: 0.8352\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3106 - accuracy: 0.8791 - val_loss: 0.3359 - val_accuracy: 0.8352\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2985 - accuracy: 0.8764 - val_loss: 0.3383 - val_accuracy: 0.8352\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2709 - accuracy: 0.8956 - val_loss: 0.2975 - val_accuracy: 0.8681\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2628 - accuracy: 0.9066 - val_loss: 0.2820 - val_accuracy: 0.8791\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2439 - accuracy: 0.9011 - val_loss: 0.2892 - val_accuracy: 0.8681\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2339 - accuracy: 0.9121 - val_loss: 0.2630 - val_accuracy: 0.8681\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2213 - accuracy: 0.9176 - val_loss: 0.2457 - val_accuracy: 0.8901\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2135 - accuracy: 0.9313 - val_loss: 0.2457 - val_accuracy: 0.8901\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2048 - accuracy: 0.9176 - val_loss: 0.2367 - val_accuracy: 0.9011\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1944 - accuracy: 0.9231 - val_loss: 0.2172 - val_accuracy: 0.8901\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1886 - accuracy: 0.9313 - val_loss: 0.2091 - val_accuracy: 0.9121\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1800 - accuracy: 0.9313 - val_loss: 0.2096 - val_accuracy: 0.9011\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1750 - accuracy: 0.9286 - val_loss: 0.1971 - val_accuracy: 0.9011\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1701 - accuracy: 0.9368 - val_loss: 0.1913 - val_accuracy: 0.9121\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1633 - accuracy: 0.9423 - val_loss: 0.1758 - val_accuracy: 0.9231\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1596 - accuracy: 0.9451 - val_loss: 0.1729 - val_accuracy: 0.9231\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1557 - accuracy: 0.9478 - val_loss: 0.1762 - val_accuracy: 0.9121\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1505 - accuracy: 0.9478 - val_loss: 0.1639 - val_accuracy: 0.9231\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1488 - accuracy: 0.9423 - val_loss: 0.1529 - val_accuracy: 0.9341\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1460 - accuracy: 0.9533 - val_loss: 0.1605 - val_accuracy: 0.9121\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1381 - accuracy: 0.9533 - val_loss: 0.1451 - val_accuracy: 0.9341\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1331 - accuracy: 0.9505 - val_loss: 0.1376 - val_accuracy: 0.9341\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1336 - accuracy: 0.9478 - val_loss: 0.1408 - val_accuracy: 0.9341\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1258 - accuracy: 0.9560 - val_loss: 0.1298 - val_accuracy: 0.9341\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1277 - accuracy: 0.9588 - val_loss: 0.1271 - val_accuracy: 0.9341\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9560 - val_loss: 0.1404 - val_accuracy: 0.9341\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1205 - accuracy: 0.9560 - val_loss: 0.1230 - val_accuracy: 0.9451\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1145 - accuracy: 0.9643 - val_loss: 0.1160 - val_accuracy: 0.9451\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1158 - accuracy: 0.9643 - val_loss: 0.1127 - val_accuracy: 0.9451\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.9533 - val_loss: 0.1237 - val_accuracy: 0.9451\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1109 - accuracy: 0.9615 - val_loss: 0.1072 - val_accuracy: 0.9560\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.9698 - val_loss: 0.1056 - val_accuracy: 0.9451\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1052 - accuracy: 0.9643 - val_loss: 0.1077 - val_accuracy: 0.9451\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9643 - val_loss: 0.1004 - val_accuracy: 0.9560\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1007 - accuracy: 0.9725 - val_loss: 0.0972 - val_accuracy: 0.9560\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 0.9725 - val_loss: 0.0959 - val_accuracy: 0.9560\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0967 - accuracy: 0.9698 - val_loss: 0.0954 - val_accuracy: 0.9560\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0962 - accuracy: 0.9698 - val_loss: 0.0933 - val_accuracy: 0.9560\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0934 - accuracy: 0.9698 - val_loss: 0.0900 - val_accuracy: 0.9560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23d85764bb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=load_breast_cancer()\n",
    "x=dataset['data']\n",
    "y=dataset['target']\n",
    "sacle=MinMaxScaler()\n",
    "x_scale=sacle.fit_transform(x)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scale,y,test_size=0.2,random_state=45)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "Modal=Sequential([\n",
    " Dense(32,input_shape=x[0].shape,activation=\"tanh\"),\n",
    " Dense(100,activation=\"tanh\"),\n",
    " Dense(1,activation=\"tanh\")\n",
    "])\n",
    "Modal.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "Modal.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61815c-46a3-4a5c-8de2-41cc6bbbbf41",
   "metadata": {},
   "source": [
    "# 4.) Leaky relu :- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c9f7424-1f91-4794-bc88-08f0deb8176d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 24ms/step - loss: 1.1826 - accuracy: 0.2692 - val_loss: 0.8844 - val_accuracy: 0.3626\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.8331 - accuracy: 0.5192 - val_loss: 0.8578 - val_accuracy: 0.4945\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.7767 - accuracy: 0.5934 - val_loss: 0.7759 - val_accuracy: 0.5055\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5962 - val_loss: 0.6696 - val_accuracy: 0.6374\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6025 - accuracy: 0.7033 - val_loss: 0.5848 - val_accuracy: 0.6923\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.7857 - val_loss: 0.5036 - val_accuracy: 0.7473\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.8269 - val_loss: 0.4465 - val_accuracy: 0.8022\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8626 - val_loss: 0.3854 - val_accuracy: 0.8462\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8764 - val_loss: 0.3472 - val_accuracy: 0.8681\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3118 - accuracy: 0.9011 - val_loss: 0.3125 - val_accuracy: 0.9011\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2864 - accuracy: 0.8901 - val_loss: 0.2920 - val_accuracy: 0.8901\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.9093 - val_loss: 0.2581 - val_accuracy: 0.9121\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2397 - accuracy: 0.9121 - val_loss: 0.2291 - val_accuracy: 0.9231\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2147 - accuracy: 0.9258 - val_loss: 0.2104 - val_accuracy: 0.9231\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1963 - accuracy: 0.9286 - val_loss: 0.1878 - val_accuracy: 0.9231\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1825 - accuracy: 0.9313 - val_loss: 0.1814 - val_accuracy: 0.9231\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.9341 - val_loss: 0.1665 - val_accuracy: 0.9231\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.9451 - val_loss: 0.1559 - val_accuracy: 0.9231\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.9396 - val_loss: 0.1532 - val_accuracy: 0.9231\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1434 - accuracy: 0.9533 - val_loss: 0.1348 - val_accuracy: 0.9341\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9533 - val_loss: 0.1352 - val_accuracy: 0.9231\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1287 - accuracy: 0.9588 - val_loss: 0.1195 - val_accuracy: 0.9451\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1241 - accuracy: 0.9643 - val_loss: 0.1151 - val_accuracy: 0.9341\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1186 - accuracy: 0.9560 - val_loss: 0.1120 - val_accuracy: 0.9451\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9588 - val_loss: 0.1028 - val_accuracy: 0.9451\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9670 - val_loss: 0.0984 - val_accuracy: 0.9560\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1049 - accuracy: 0.9698 - val_loss: 0.0950 - val_accuracy: 0.9560\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9615 - val_loss: 0.0906 - val_accuracy: 0.9560\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0963 - accuracy: 0.9643 - val_loss: 0.0867 - val_accuracy: 0.9560\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0937 - accuracy: 0.9698 - val_loss: 0.0834 - val_accuracy: 0.9670\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0905 - accuracy: 0.9670 - val_loss: 0.0811 - val_accuracy: 0.9670\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0902 - accuracy: 0.9725 - val_loss: 0.0787 - val_accuracy: 0.9670\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9643 - val_loss: 0.0801 - val_accuracy: 0.9670\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9670 - val_loss: 0.0748 - val_accuracy: 0.9670\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0856 - accuracy: 0.9670 - val_loss: 0.0779 - val_accuracy: 0.9670\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9725 - val_loss: 0.0725 - val_accuracy: 0.9670\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9643 - val_loss: 0.0734 - val_accuracy: 0.9780\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9698 - val_loss: 0.0689 - val_accuracy: 0.9670\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9725 - val_loss: 0.0688 - val_accuracy: 0.9670\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9725 - val_loss: 0.0650 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0724 - accuracy: 0.9753 - val_loss: 0.0645 - val_accuracy: 0.9670\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9698 - val_loss: 0.0631 - val_accuracy: 0.9670\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0678 - accuracy: 0.9753 - val_loss: 0.0622 - val_accuracy: 0.9670\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9753 - val_loss: 0.0607 - val_accuracy: 0.9670\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0710 - accuracy: 0.9698 - val_loss: 0.0601 - val_accuracy: 0.9670\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0665 - accuracy: 0.9835 - val_loss: 0.0613 - val_accuracy: 0.9670\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 0.0594 - val_accuracy: 0.9670\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.0563 - val_accuracy: 0.9670\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9808 - val_loss: 0.0563 - val_accuracy: 0.9670\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9780 - val_loss: 0.0575 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23d8788e020>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=load_breast_cancer()\n",
    "x=dataset['data']\n",
    "y=dataset['target']\n",
    "sacle=MinMaxScaler()\n",
    "x_scale=sacle.fit_transform(x)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scale,y,test_size=0.2,random_state=45)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "Modal=Sequential([\n",
    " Dense(32,input_shape=x[0].shape,activation=LeakyReLU(alpha=0.1)),\n",
    " Dense(100,activation=\"tanh\"),\n",
    " Dense(1,activation=\"tanh\")\n",
    "])\n",
    "Modal.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "Modal.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccbc44-f8d1-45db-8ad0-9ded8903b0d8",
   "metadata": {},
   "source": [
    "# Result :- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c2f36-bf87-4f4b-9551-51ebe3f37e0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### 1.) Sigmoid -    loss: 0.1538 - accuracy: 0.9478 - val_loss: 0.1267 - val_accuracy: 0.9670\n",
    "\n",
    "### 2.) tanh    -    loss: 0.0934 - accuracy: 0.9698 - val_loss: 0.0900 - val_accuracy: 0.9560\n",
    "\n",
    "### 4.) Relu    -   loss: 0.0934 - accuracy: 0.9698 - val_loss: 0.0900 - val_accuracy: 0.9560\n",
    "\n",
    "### 5.) LeakyRelu -  loss: 0.0602 - accuracy: 0.9780 - val_loss: 0.0575 - val_accuracy: 0.9670\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa1496-034c-425c-836f-b5040631a37a",
   "metadata": {},
   "source": [
    "# Note :-\n",
    "## Bais = 100% - traning_score < 5%\n",
    "## variance = traning_score - testing_score < 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f2021-3612-4ea7-aa3a-50a59f7fad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
