{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ab7e3f-929f-4398-b7c7-b67506d32f0f",
   "metadata": {},
   "source": [
    "# Loss Function :-\n",
    "## A loss function measures how good a neural network model is in performing a certain task, which in most cases is regression or classification. We always try to minimize the value of the loss function .\n",
    "# _____________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda21ce2",
   "metadata": {},
   "source": [
    "# Loss v/s Cost Function :-\n",
    "## When loss calculate on single data then it says to be loss func. but on otherhand it calculate on whole data set it says to be cost func.\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://miro.medium.com/v2/resize:fit:569/1*gZ9IpHVsiWOYzUks98pd0Q.png\" alt=\"2\" border=\"0\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ecb5ce-9823-4d63-adc7-8fa19b75c8b8",
   "metadata": {},
   "source": [
    "# There are many types of lost function some most frequantly use in industry are given below :-\n",
    "\n",
    "## 1> Binary Crossentropy\n",
    "\n",
    "## 2> Categorical Crossentropy\n",
    "\n",
    "## 3> Mean Squared Error (MSE)\n",
    "\n",
    "## 4> Mean Absolute Error (MAE)\n",
    "\n",
    "## 5> Huber Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfacb45-7cb3-4169-a0d3-b9b679b7ed75",
   "metadata": {},
   "source": [
    "# __________________________________________________________________\n",
    "#\n",
    "# 1>Binary Crossentropy :-\n",
    "## -> Binary Cross Entropy is a method used to measure how well a model is doing at predicting the correct outcome when there are only two possible classes (like \"yes\" or \"no\", \"spam\" or \"not spam\", etc.).\n",
    "<pre><h1>                          OR                               </h1></pre>\n",
    "## -> Binary Crossentropy is a loss function commonly used in binary classification tasks in machine learning and deep learning. It measures the difference between two probability distributions: the predicted probability distribution output by a model and the actual distribution represented by the labels.\n",
    "\n",
    "# Note: Binary cross entropy always used with two classes in our datasets. for : \"spam\",\"not spam\" kind of class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f030f7f-d675-486e-aa7f-5b4d968a8dae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Formula used by Binary Crossentropy :- \n",
    "\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://arize.com/wp-content/uploads/2022/11/log-loss-1.png\" alt=\"2\" border=\"0\"></a>\n",
    "\n",
    "# Where:-\n",
    "# * N is total no. of datapoints.\n",
    "# * y is the true label (either 0 or 1).\n",
    "# * p is the predicted probability of the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c046e08-77e2-4c91-a5f4-1ac18a41a5b9",
   "metadata": {},
   "source": [
    "# Code :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4503c545-16b9-4e3b-a64f-716c4bb4a730",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Paramjeet\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "8/8 [==============================] - 1s 36ms/step - loss: 1.0013 - accuracy: 0.3571 - val_loss: 0.8972 - val_accuracy: 0.5934\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8054 - accuracy: 0.6181 - val_loss: 0.7434 - val_accuracy: 0.4835\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6702 - accuracy: 0.6044 - val_loss: 0.6371 - val_accuracy: 0.5934\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5806 - accuracy: 0.7225 - val_loss: 0.5453 - val_accuracy: 0.7363\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.8214 - val_loss: 0.4658 - val_accuracy: 0.8132\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.8544 - val_loss: 0.3994 - val_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3719 - accuracy: 0.8681 - val_loss: 0.3597 - val_accuracy: 0.8571\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3234 - accuracy: 0.8819 - val_loss: 0.3431 - val_accuracy: 0.8352\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3023 - accuracy: 0.8819 - val_loss: 0.3025 - val_accuracy: 0.8901\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.9066 - val_loss: 0.3168 - val_accuracy: 0.8352\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8159 - val_loss: 0.4795 - val_accuracy: 0.7582\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8269 - val_loss: 0.2956 - val_accuracy: 0.8462\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.9011 - val_loss: 0.2571 - val_accuracy: 0.9011\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2951 - accuracy: 0.9093 - val_loss: 0.2440 - val_accuracy: 0.9121\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2369 - accuracy: 0.9203 - val_loss: 0.2380 - val_accuracy: 0.9121\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2268 - accuracy: 0.9203 - val_loss: 0.2333 - val_accuracy: 0.9011\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2207 - accuracy: 0.9203 - val_loss: 0.2236 - val_accuracy: 0.9121\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2140 - accuracy: 0.9231 - val_loss: 0.2059 - val_accuracy: 0.9121\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2041 - accuracy: 0.9258 - val_loss: 0.2010 - val_accuracy: 0.9121\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9258 - val_loss: 0.1905 - val_accuracy: 0.9231\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1900 - accuracy: 0.9231 - val_loss: 0.1852 - val_accuracy: 0.9231\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.9258 - val_loss: 0.1796 - val_accuracy: 0.9341\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1772 - accuracy: 0.9286 - val_loss: 0.1745 - val_accuracy: 0.9231\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.9341 - val_loss: 0.1666 - val_accuracy: 0.9341\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1651 - accuracy: 0.9341 - val_loss: 0.1609 - val_accuracy: 0.9341\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1592 - accuracy: 0.9451 - val_loss: 0.1570 - val_accuracy: 0.9341\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1546 - accuracy: 0.9423 - val_loss: 0.1513 - val_accuracy: 0.9341\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1520 - accuracy: 0.9341 - val_loss: 0.1469 - val_accuracy: 0.9341\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1500 - accuracy: 0.9396 - val_loss: 0.1489 - val_accuracy: 0.9341\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9505 - val_loss: 0.1348 - val_accuracy: 0.9451\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1383 - accuracy: 0.9478 - val_loss: 0.1309 - val_accuracy: 0.9341\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1346 - accuracy: 0.9533 - val_loss: 0.1276 - val_accuracy: 0.9451\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1310 - accuracy: 0.9560 - val_loss: 0.1221 - val_accuracy: 0.9451\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9588 - val_loss: 0.1163 - val_accuracy: 0.9560\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.9560 - val_loss: 0.1158 - val_accuracy: 0.9451\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9560 - val_loss: 0.1087 - val_accuracy: 0.9451\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1211 - accuracy: 0.9533 - val_loss: 0.1121 - val_accuracy: 0.9560\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.9560 - val_loss: 0.1022 - val_accuracy: 0.9560\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1127 - accuracy: 0.9533 - val_loss: 0.0993 - val_accuracy: 0.9560\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1105 - accuracy: 0.9533 - val_loss: 0.0975 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.9560 - val_loss: 0.0957 - val_accuracy: 0.9670\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9560 - val_loss: 0.0895 - val_accuracy: 0.9560\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.1069 - accuracy: 0.9615 - val_loss: 0.0870 - val_accuracy: 0.9780\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1017 - accuracy: 0.9588 - val_loss: 0.0902 - val_accuracy: 0.9670\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1010 - accuracy: 0.9588 - val_loss: 0.0828 - val_accuracy: 0.9670\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0968 - accuracy: 0.9588 - val_loss: 0.0822 - val_accuracy: 0.9670\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0955 - accuracy: 0.9615 - val_loss: 0.0806 - val_accuracy: 0.9670\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0942 - accuracy: 0.9643 - val_loss: 0.0775 - val_accuracy: 0.9670\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.9615 - val_loss: 0.0748 - val_accuracy: 0.9780\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 0.9643 - val_loss: 0.0763 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x13a7a7a5b40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset=load_breast_cancer()\n",
    "x=dataset['data']\n",
    "y=dataset['target']\n",
    "sacle=MinMaxScaler()\n",
    "x_scale=sacle.fit_transform(x)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_scale,y,test_size=0.2,random_state=45)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "Modal=Sequential([\n",
    " Dense(32,input_shape=x[0].shape,activation=\"tanh\"),\n",
    " Dense(100,activation=\"tanh\"),\n",
    " Dense(1,activation=\"tanh\")\n",
    "])\n",
    "Modal.compile(optimizer=Adam(learning_rate=0.001),loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "Modal.fit(X_train,y_train,epochs=50,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ab9efb",
   "metadata": {},
   "source": [
    "# MSE (Mean Squared error):- \n",
    "## ->  Mean squared error (MSE) measures the amount of error in statistical models. It assesses the average squared difference between the observed and predicted values. When a model has no error, the MSE equals zero. As model error increases, its value increases. The mean squared error is also known as the mean squared deviation (MSD).\n",
    "\n",
    "## For example, in regression, the mean squared error represents the average squared residual.\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://i0.wp.com/statisticsbyjim.com/wp-content/uploads/2017/04/residuals.png?resize=300%2C186&ssl=1\" alt=\"2\" border=\"0\"></a>\n",
    "## Image depicting the relationship between the residuals and the mean squared error.\n",
    "\n",
    "## As the data points fall closer to the regression line, the model has less error, decreasing the MSE. A model with less error produces more precise predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb15a5c",
   "metadata": {},
   "source": [
    "# MSE Formula :-\n",
    "<a href=\"http://ibb.co/f8Epqx\"><img src=\"https://i0.wp.com/statisticsbyjim.com/wp-content/uploads/2021/11/mse_formula.png?resize=246%2C78&ssl=1\" alt=\"2\" border=\"0\"></a>\n",
    "## Where:\n",
    "\n",
    "* yi is the ith observed value.\n",
    "* ŷi is the corresponding predicted value.\n",
    "* n = the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb0192",
   "metadata": {},
   "source": [
    "# Advantage :-\n",
    "## 1.) Easy to intreupt.\n",
    "## 2.) Differentiable for gredient desent in otherword gd apply easily .\n",
    "## 3.) 1 local minima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfdf52",
   "metadata": {},
   "source": [
    "# Disadvantage :-\n",
    "## 1.) Error unit (squared) 2^1=2,2^2=4,2^3=8,2^4=16,......\n",
    "## 2.) Not Robust to outlier (Too handle the outlier it daveate the line by gernating big weight.).\n",
    "## 3.) last neuron activation layer must be linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c51b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
